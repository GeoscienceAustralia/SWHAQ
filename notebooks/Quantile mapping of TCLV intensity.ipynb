{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile mapping of TCLV intensity\n",
    "\n",
    "This notebook is used to map the intensity of TCLVs to the observed historical distribution of intensity. \n",
    "\n",
    "We work with the central pressure deficit $\\Delta p_c = p_{oci} - p_{c}$, where $p_{oci}$ is the pressure of the outermost closed isobar (sometimes also referred to as environmental pressure $p_{env}$) and $p_c$ is the minimum central pressure. We use $\\Delta p_c$, as this is the variable used in TCRM to model intensity. $p_c$ is also more widely recorded in the Australian region, for reasons that I'll not go into here. \n",
    "\n",
    "Irrespective of the variable chosen, regionally downscaled climate models, even at 10 km grid spacing, do not sufficiently resolve the dynamics that drive TC intensity. To accurately simulate maximum intensity (represented by surface wind speed) arguably requires a convection-allowing model, which usually entails grid spacings less than 2 km (e.g. Gentry and Lackmann, 2010; Walsh _et al_., 2013). Such modelling efforts are beyond the scope of this project, so we rely on scaling the intensity to address the issue.\n",
    "\n",
    "We use a quantile mapping approach to adjust the $\\Delta p_c$ of the TCLVs extracted for future climate projections which does not _a priori_ assume a stationary relationship in the scaling function (as we have previously done, for example, in Arthur and Woolf, 2015). Cannon _et al._ (2015) describe a method for bias correction of climate variables that conserves relative changes in quantiles between current and future climate regimes. Called Quantile Delta Mapping (QDM), the method ensures that climate sensitivity of the underlying climate model remains unaffected by the correction process. The concepts described in Cannon _et al._ have been applied to a range of other climate variables - e.g. Bhatia _et al._ (2019) have applied QDM to intensity changes of simulated TCs in high-resolution simulations.\n",
    "\n",
    "Changes in frequency and track behavoiur - both key factors in understanding likelihood of extreme winds - are drawn directly from the TCLV data and are examined in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as feature\n",
    "import statsmodels.api as sm\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import shapely.geometry as sg\n",
    "from shapely.geometry import box as sbox\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.stats as stats\n",
    "\n",
    "# From TCRM codebase\n",
    "from Utilities.loadData import maxWindSpeed\n",
    "\n",
    "from builtins import str\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines a number of functions that are used to load and filter the track data generated by the regional downscaling simulations. \n",
    "\n",
    "Filters are applied to eliminate spurious tracks that have a short lifetime. These spurious tracks are picked up by the detection and tracking method, but are not persisted for a sufficient time period (36 hours), which leads to an anomolous occurence of TCLVs around the Solomon Islands in some of the model output. \n",
    "\n",
    "A spatial filter is used to select only those tracks that pass through the study region - in this case Queensland and the Coral Sea. The regional downscaling was focused over the Queensland region (using a cubic-conformal grid configuration), so the marginal regions are unlikely to resolve the dynamics of the inner core of TCLVs. As the grid spacing of the computational grid increases, the fine scale features that control intensity of TCLVs will not be as well resolved, which will affect the distribution of intensity in simulated events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_track_file(filename):\n",
    "    \"\"\"\n",
    "    Load a TCLV file into a :class:`pandas.DataFrame`, and add a field \n",
    "    representing the age of each TCLV in hours, and the pressure difference.\n",
    "    \n",
    "    :param str filename: Path to a TCLV data file\n",
    "    \n",
    "    :returns: :class:`pandas.DataFrame`\n",
    "    \"\"\"\n",
    "    # This assumes the format of the TCLV files is identical\n",
    "    columns = ['num', 'year', 'month', 'day', 'hour', 'lon', 'lat',\n",
    "               'pmin', 'vorticity', 'vmax', 'tanomsum','tanomdiff',\n",
    "               'pmslanom', 'poci', 'reff','ravg','asym']\n",
    "    df = pd.read_csv(filename, delimiter=' ', skipinitialspace=True,\n",
    "                     names=columns, parse_dates={'datetime':[1,2,3,4]},\n",
    "                     keep_date_col=True, \n",
    "                     dtype={'year':int, 'month':int, 'day':int})\n",
    "    df['dt'] = df.groupby('num')['datetime'].apply(lambda x: x.diff())\n",
    "    df['dt'] = df['dt'].transform(lambda x: x.total_seconds())\n",
    "\n",
    "    df['age'] = df.groupby('num')['dt'].apply(np.cumsum).fillna(0)/3600.\n",
    "    # Throw in the pressure deficit for good measure:\n",
    "    df['pdiff'] = df['poci'] - df['pmin']\n",
    "    # And normalised intensity. This is the intensity at any given time,\n",
    "    # dividied by the lifetime maximum intensity for each unique event\n",
    "    df['ni'] = df.pdiff / df.groupby('num').pdiff.transform(np.max)\n",
    "\n",
    "    return df\n",
    "\n",
    "def filter_tracks(df, start_year=1980, end_year=2010, zeta=0, age=36):\n",
    "    \"\"\"\n",
    "    Takes a `DataFrame` and filters on the basis of a prescribed vorticity \n",
    "    threshold, lifetime and a given time period.\n",
    "    \n",
    "    :param df: :class:`pandas.DataFrame` that holds the TCLV data\n",
    "    :param int start_year: Starting year of the time period to filter\n",
    "    :param int end_year: End year of the period to filter\n",
    "    :param float zeta: Vorticity threshold to filter the TCLV data. \n",
    "                       This can be a positive value, as we filter on the\n",
    "                       absolute value of the field.\n",
    "    :param int age: Minimum age of the TCLVs in hours\n",
    "    \n",
    "    \"\"\"\n",
    "    tracks = df.groupby('num')\n",
    "    filterdf = tracks.filter(lambda x: (x['datetime'].dt.year.min() >= start_year) &\\\n",
    "                                       (x['datetime'].dt.year.max() <= end_year) &\\\n",
    "                                       (x['age'].max() >= age) &\\\n",
    "                                       (np.abs(x['vorticity'].min()) > zeta))\n",
    "    return filterdf\n",
    "\n",
    "def filter_tracks_domain(df, minlon=90, maxlon=180, minlat=-40, maxlat=0):\n",
    "    \"\"\"\n",
    "    Takes a `DataFrame` and filters on the basis of whether the track interscts\n",
    "    the given domain, which is specified by the minimum and maximum longitude and \n",
    "    latitude.\n",
    "    \n",
    "    NOTE: This assumes the tracks and bounding box are in the same geographic \n",
    "    coordinate system (i.e. generally a latitude-longitude coordinate system). \n",
    "    It will NOT support different projections (e.g. UTM data for the bounds and\n",
    "    geographic for the tracks).\n",
    "    \n",
    "    NOTE: This doesn't work if there is only one point for the track. \n",
    "    \n",
    "    :param df: :class:`pandas.DataFrame` that holds the TCLV data\n",
    "    :param float minlon: minimum longitude of the bounding box\n",
    "    :param float minlat: minimum latitude of the bounding box\n",
    "    :param float maxlon: maximum longitude of the bounding box\n",
    "    :param float maxlat: maximum latitude of the bounding box\n",
    "    \"\"\"\n",
    "    domain = sbox(minlon, minlat, maxlon, maxlat, ccw=False)\n",
    "    tracks = df.groupby('num')\n",
    "    tempfilter = tracks.filter(lambda x: len(x) > 1)\n",
    "    tempfilter.head()\n",
    "    filterdf = tempfilter.groupby('num').filter(lambda x: LineString(zip(x['lon'], x['lat'])).intersects(domain))\n",
    "    return filterdf\n",
    "\n",
    "\n",
    "def calculateMaxWind(df, dtname='ISO_TIME'):\n",
    "    \"\"\"\n",
    "    Calculate a maximum gust wind speed based on the central pressure deficit and the \n",
    "    wind-pressure relation defined in Holland (2008). This uses the function defined in \n",
    "    the TCRM code base, and simply passes the correct variables from the data frame\n",
    "    to the function\n",
    "    \n",
    "    This returns a `DataFrame` with an additional column (`vmax`), which represents an estimated\n",
    "    0.2 second maximum gust wind speed.\n",
    "    \"\"\"\n",
    "    idx = df.num.values\n",
    "    varidx = np.ones(len(idx))\n",
    "    varidx[1:][idx[1:]==idx[:-1]] = 0\n",
    "    \n",
    "    dt = (df[dtname] - df[dtname].shift()).fillna(pd.Timedelta(seconds=0)).apply(lambda x: x / np.timedelta64(1,'h')).astype('int64') % (24*60)\n",
    "    df['vmax'] = maxWindSpeed(varidx, dt.values, df.lon.values, df.lat.values,\n",
    "                              df.pmin.values, df.poci.values, gustfactor=1.223)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/tclv/\"\n",
    "regex = r'all_tracks_(.+)_(rcp\\d+)\\.dat'\n",
    "labels = ['TD', 'TC1', 'TC2', 'TC3', 'TC4', 'TC5']\n",
    "catpal = sns.blend_palette([(0.000, 0.627, 0.235), (0.412, 0.627, 0.235), \n",
    "                            (0.663, 0.780, 0.282), (0.957, 0.812, 0.000), \n",
    "                            (0.925, 0.643, 0.016), (0.835, 0.314, 0.118),\n",
    "                            (0.780, 0.086, 0.118)], 6)\n",
    "dist = stats.lognorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are referenced in the following way::\n",
    "\n",
    "* `s` = simulated\n",
    "* `ref` = reference time period (1981-2010)\n",
    "* `fut` = future time period (2021-2040, 2041-2060, 2061-2080 or 2081-2100)\n",
    "* `obstc` = observed TC events (using IBTrACS, 1981-2010)\n",
    "* `b` = bias-corrected\n",
    "\n",
    "Firstly load the IBTrACS data and extract the relevant tracks for the region of interest. We retain only those tracks that have a vaild $\\Delta p$ value and enter the simulation domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = pd.read_csv('../data/ibtracs.since1980.list.v04r00.csv', \n",
    "                       skiprows=[1],\n",
    "                       usecols=[0,6,8,9,11,113],\n",
    "                       na_values=[' '],\n",
    "                       parse_dates=[1])\n",
    "best.rename(columns={'SID':'num', 'LAT': 'lat', 'LON':'lon', 'WMO_PRES':'pmin', 'BOM_POCI':'poci'}, inplace=True)\n",
    "best = best[best.poci.notnull() & best.pmin.notnull()]\n",
    "best['pdiff'] = best.poci - best.pmin\n",
    "best = best[best.pdiff > 0]\n",
    "obstc = filter_tracks_domain(best, 135, 160, -25, -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines(resolution='10m', color='black', linewidth=1)\n",
    "ax.add_feature(feature.BORDERS)\n",
    "gl = ax.gridlines(linestyle=\":\", draw_labels=True)\n",
    "ax.add_feature(feature.LAND, zorder=0)\n",
    "for k, v in obstc.groupby('num'):\n",
    "    ax.plot(v['lon'], v['lat'])\n",
    "\n",
    "ax.add_patch(mpatches.Rectangle(xy=[135, -25], width=25, height=15,\n",
    "                                fill=False, edgecolor='k', linewidth=3,\n",
    "                                transform=ccrs.PlateCarree())\n",
    "             )\n",
    "None\n",
    "plt.savefig(pjoin(path, \"observed_tracks.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above plots all tracks that enter the selected domain (135-170$^\\circ$E, 5-35$^\\circ$S), and have a $p_{oci}$ defined in the historical record. This variable was not widely reported, and then only those events that are in the Bureau of Meteorology's area of responsibility have this field (this leads to the artificial boundary at 160$^\\circ$E). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the quantile delta mapping function\n",
    "\n",
    "Here is where we develop the QDM algorithm. The algorithm is based on the QDM described by Cannon _et al._ (2015), where the relative change in quantiles between a reference period and the future period are preserved. \n",
    "\n",
    "$\\delta_{fut} = \\dfrac{Q_{fut}}{F_{ref}^{-1}\\left[ F_{fut} ( Q_{fut} ) \\right]} $ \n",
    "\n",
    "$Q_{futb} = F_{obs}^{-1} \\left[ F_{fut} (Q_{fut}) \\right] \\times \\delta_{fut} $\n",
    "\n",
    "$\\delta_{fut}$ is the relative change in the quantiles between the simulated reference data ('sreftclv') and the simulated future data ('sfuttclv'). $Q_{fut}$ is the quantile of the simulated future data. $F_{fut}$ and $F_{ref}^{-1}$ are a CDF of the simulated future data and an inverse CDF of the simulated reference data respectively. Finally, $F_{obs}^{-1}$ is the inverse CDF of the observed data, and $Q_{futb}$ are the corrected quantiles of the future data.\n",
    "\n",
    "In this framework, the algorithm is independent of the selection of distribution, which would be data-dependent, and more generally specific to the variable that is being corrected. We begin by fitting a lognormal distribution to the $\\Delta p_c$ values in each of the observed, reference and future collections. \n",
    "\n",
    "For our analysis, the reference period is 1981-2010. Future periods will be based on 20-year time slices centred on 2030, 2050, 2070 and 2090. This will give four different corrections for each model and RCP.  \n",
    "\n",
    "The resulting bias-corrected $\\Delta p_c$ values will be applied to the TCLV data, which will in turn be used as input to hazard simulations for the reference and future climate periods. As a final check, we will calculate a maximum wind speed based on Holland's (2008) wind pressure relation, and explore changes in the occurrence of severe TCs (i.e. category 3-5 TCs based on the Bureau of Meteorology's TC intensity scale). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qdm(vobs, vref, vfut, dist=stats.lognorm):\n",
    "    \"\"\"\n",
    "    Calculate the quantile delta mapping for a collection of simulated data. \n",
    "    \n",
    "    This function is based on the formulation described in Cannon _et al._ (2015) and Heo _et al._ (2019).\n",
    "    \n",
    "    :param vobs: numpy.array of observed values\n",
    "    :param vref: numpy.array of reference period values (simulated)\n",
    "    :param vfut: numpy.array of future period values (simulated)\n",
    "    :param func dist: Distribution function to use. This must have `fit`, `pdf`, `cdf` and `ppf` methods defined, \n",
    "                      as used in `scipy.stats.rv_continuous` distributions. Default is `scipy.stats.lognorm`.\n",
    "                      \n",
    "    :returns: `vfutb` a numpy.array of bias corrected future values. \n",
    "    \"\"\"\n",
    "    \n",
    "    pobs = dist.fit(vobs, loc=0, scale=1)\n",
    "    pref = dist.fit(vref, loc=0, scale=1)\n",
    "    pfut = dist.fit(vfut, loc=0, scale=1)\n",
    "    \n",
    "    # CDF of future, at the value of the future data points\n",
    "    Fsf = dist.cdf(vfut, *pfut)\n",
    "    # Inverse cdf of reference period distribution, evaluated at future CDF\n",
    "    # values\n",
    "    invFsr = dist.ppf(Fsf, *pref)\n",
    "    \n",
    "    # Relative change in values\n",
    "    delta = vfut / invFsr\n",
    "    vfutb = dist.ppf(Fsf, *pobs) * delta\n",
    "    \n",
    "    return vfutb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we explore the distribution of $\\Delta p_c$ for the reference period (1981-2010) in each of the models, and the best track archive. The figure below shows the histogram of $\\Delta p_c$, with a fitted lognormal distribution to each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdata = {}\n",
    "regex = r'all_tracks_(.+)_(rcp\\d+)\\.dat'\n",
    "ens45 = []\n",
    "ens85 = []\n",
    "for i, fname in enumerate(os.listdir(path)):\n",
    "    if fname==\"all_tracks_ERAIntQ_rcp85.dat\":\n",
    "        continue\n",
    "    m = re.match(regex, fname)\n",
    "    try:\n",
    "        model, rcp = m.group(1, 2)\n",
    "    except AttributeError: \n",
    "        # Catch the case where there are other files or folders in the directory\n",
    "        continue\n",
    "    \n",
    "    filename = pjoin(path, fname)\n",
    "    df = load_track_file(filename)\n",
    "    df = filter_tracks(df)\n",
    "    df = filter_tracks_domain(df, 135, 160, -25, -10)\n",
    "    if rcp.upper() == 'RCP45':\n",
    "        ens45.append(df)\n",
    "    else:\n",
    "        ens85.append(df)\n",
    "    label = f\"{model} {rcp.upper()}\"\n",
    "    refdata[label] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdata['ENS RCP45'] = pd.concat(ens45, ignore_index=True)\n",
    "refdata['ENS RCP85'] = pd.concat(ens85, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,4, figsize=(20,20), sharex=True)\n",
    "ax = axes.flatten()\n",
    "bins = np.arange(0, 100, 5)\n",
    "refparams = pd.DataFrame(columns=['Model', 'RCP', 'mu', 'sigma', 'zeta'])\n",
    "for i, (m, df) in enumerate(refdata.items()):\n",
    "    sns.distplot(df.pdiff, ax=ax[i], kde=False, norm_hist=True)\n",
    "    model, rcp = m.split(' ')\n",
    "    popt = stats.lognorm.fit(df.pdiff, loc=0, scale=1)\n",
    "    refparams = refparams.append({'Model':model, 'RCP':rcp, \n",
    "                                  'mu':popt[0], 'sigma':popt[1], 'zeta':popt[2]},\n",
    "                                ignore_index=True)\n",
    "    fitline = stats.lognorm.pdf(np.arange(0, 101), *popt, )\n",
    "    ax[i].plot(np.arange(0,101), fitline, color='r')\n",
    "    ax[i].set_title(\"{0}\\n({1:.4f}, {2:.4f}, {3:.4f})\".format(m, *popt))\n",
    " \n",
    "\n",
    "# Add the IBTrACS as reference\n",
    "#sns.distplot(obstc.pdiff, fit=stats.lognorm, kde=False, color='red', ax=ax[-1])\n",
    "obsparams = stats.lognorm.fit(obstc.pdiff, loc=0, scale=1)\n",
    "#ax[-1].set_title(\"IBTrACS\\n({0:.4f}, {1:.4f}, {2:.4f})\".format(*obsparams))\n",
    "fig.tight_layout()\n",
    "plt.savefig(pjoin(path, \"reference_distribution.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,5), sharey=True)\n",
    "x = np.arange(0, 100)\n",
    "\n",
    "for index, row in refparams[refparams['RCP']=='RCP45'].iterrows():\n",
    "    popt = (row.mu, row.sigma, row.zeta)\n",
    "    fitline = stats.lognorm.pdf(x, *popt)\n",
    "    if row.Model == 'ENS':\n",
    "        ax[0].plot(x, fitline, color='b')\n",
    "    else:\n",
    "        ax[0].plot(x, fitline, color='k')\n",
    "        \n",
    "ax[0].plot(x, stats.lognorm.pdf(x, *obsparams), 'r')\n",
    "ax[0].set_title(\"RCP4.5\")\n",
    "\n",
    "\n",
    "for index, row in refparams[refparams['RCP']=='RCP85'].iterrows():\n",
    "    popt = (row.mu, row.sigma, row.zeta)\n",
    "    fitline = stats.lognorm.pdf(x, *popt)\n",
    "    if index == 1:\n",
    "        ax[1].plot(x, fitline, color='k', label='Reference')\n",
    "    elif row.Model == 'ENS':\n",
    "        ax[1].plot(x, fitline, color='b', label='Ensemble')\n",
    "    else:\n",
    "        ax[1].plot(x, fitline, color='k')\n",
    "        \n",
    "ax[1].plot(x, stats.lognorm.pdf(x, *obsparams), 'r', label='Observations')\n",
    "ax[1].set_title(\"RCP8.5\")\n",
    "fig.tight_layout()\n",
    "ax[0].set_xlabel(r\"$\\Delta p_c$ (hPa)\")\n",
    "ax[0].set_ylabel(\"Probability\")\n",
    "ax[1].set_xlabel(r\"$\\Delta p_c$ (hPa)\")\n",
    "ax[1].legend()\n",
    "None\n",
    "plt.savefig(pjoin(path, 'uncorrected_distribution_by_RCP_reference.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the models produce $\\Delta p_c$ distributions that follow a lognormal distribution, but all are markedly different from the IBTrACS distribution (which is also a lognormal distribution). All the models have a lower mean compared to the IBTrACS data, indicative that the models are unable to replicate the larger $\\Delta p_c$ values in the observed record. There appears to be two families of models, but I'm yet to explore which is which, and further to that, whether these are consistent between the reference period and the future period (but we could do that based on figures below).\n",
    "\n",
    "However, that the distributions are all nominally lognormal, as is the observed distribution, gives confidence that the QDM approach will be suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refparams.groupby(['RCP']).agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's little difference between the mean distributions for RCP8.5 and RCP4.5 models, based on the reference period. Again, this is an expected result, as the models should be simulating a common baseline period (the climate forcing in the reference period is common across the CMIP models [ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load up the data for a future period and look at the distributions of $\\Delta p_c$ for the future data. For this demonstration, the future period is 2081-2100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=2081\n",
    "end=2100\n",
    "futdata = {}\n",
    "ens45 = []\n",
    "ens85 = []\n",
    "for i, f in enumerate(os.listdir(path)):\n",
    "    # Exclude the ERA Interim data\n",
    "    if f==\"all_tracks_ERAIntQ_rcp85.dat\":\n",
    "        continue\n",
    "    m = re.match(regex, f)\n",
    "    try:\n",
    "        model, rcp = m.group(1, 2)\n",
    "    except AttributeError:\n",
    "        continue\n",
    "    \n",
    "    filename = pjoin(path, f)\n",
    "    df = load_track_file(filename)\n",
    "    df = filter_tracks(df, start_year=start, end_year=end)\n",
    "    df = filter_tracks_domain(df, 135, 160, -25, -10)\n",
    "    if rcp.upper() == 'RCP45':\n",
    "        ens45.append(df)\n",
    "    else:\n",
    "        ens85.append(df)\n",
    "    label = \"{0} {1}\".format(model, rcp.upper())\n",
    "    futdata[label] = df\n",
    "    \n",
    "futdata['ENS RCP45'] = pd.concat(ens45, ignore_index=True)\n",
    "futdata['ENS RCP85'] = pd.concat(ens85, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,4, figsize=(20,20), sharex=True)\n",
    "ax = axes.flatten()\n",
    "futparams = pd.DataFrame(columns=['Model', 'RCP', 'mu', 'sigma', 'zeta'])\n",
    "for i, (m, df) in enumerate(futdata.items()):\n",
    "    model, rcp = m.split(' ')\n",
    "    sns.distplot(df.pdiff, ax=ax[i], kde=False, norm_hist=True)\n",
    "    popt = stats.lognorm.fit(df.pdiff, loc=0, scale=1)\n",
    "    fitline = stats.lognorm.pdf(np.arange(0, 101), *popt, )\n",
    "    futparams = futparams.append({'Model':model, 'RCP':rcp,\n",
    "                                  'mu':popt[0], 'sigma':popt[1], 'zeta':popt[2]},\n",
    "                                  ignore_index=True)\n",
    "    ax[i].plot(np.arange(0,101), fitline, color='r')\n",
    "    ax[i].set_title(\"{0}\\n({1:.4f}, {2:.4f}, {3:.4f})\".format(m, *popt))\n",
    " \n",
    "\n",
    "# Again, add the IBTrACS as reference\n",
    "#sns.distplot(obstc.pdiff, fit=stats.lognorm, kde=False, color='red', ax=ax[-1])\n",
    "obsparams = stats.lognorm.fit(obstc.pdiff)\n",
    "#ax[-1].set_title(\"IBTrACS\\n({0:.4f}, {1:.4f}, {2:.4f})\".format(*obsparams))\n",
    "fig.tight_layout()\n",
    "plt.savefig(pjoin(path, \"future_distribution.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,6), sharey=True)\n",
    "x = np.arange(0, 100)\n",
    "\n",
    "for index, row in futparams[refparams['RCP']=='RCP45'].iterrows():\n",
    "    popt = (row.mu, row.sigma, row.zeta)\n",
    "    fitline = stats.lognorm.pdf(x, *popt)\n",
    "    if row.Model == 'ENS':\n",
    "        ax[0].plot(x, fitline, color='b')\n",
    "    else:\n",
    "        ax[0].plot(x, fitline, color='k')\n",
    "    \n",
    "ax[0].plot(x, stats.lognorm.pdf(x, *obsparams), 'r')\n",
    "ax[0].set_title(\"RCP4.5\")\n",
    "\n",
    "\n",
    "for index, row in futparams[refparams['RCP']=='RCP85'].iterrows():\n",
    "    popt = (row.mu, row.sigma, row.zeta)\n",
    "    fitline = stats.lognorm.pdf(x, *popt)\n",
    "    if index == 1:\n",
    "        ax[1].plot(x, fitline, color='k', label='Projected')\n",
    "    elif row.Model == 'ENS':\n",
    "        ax[1].plot(x, fitline, color='b', label='Ensemble')\n",
    "    else:\n",
    "        ax[1].plot(x, fitline, color='k')\n",
    "        \n",
    "ax[1].plot(x, stats.lognorm.pdf(x, *obsparams), 'r', label='Observations')\n",
    "ax[1].set_title(\"RCP8.5\")\n",
    "fig.tight_layout()\n",
    "ax[0].set_xlabel(r\"$\\Delta p_c$ (hPa)\")\n",
    "ax[1].set_xlabel(r\"$\\Delta p_c$ (hPa)\")\n",
    "ax[1].legend()\n",
    "None\n",
    "plt.savefig(pjoin(path, 'uncorrected_distribution_by_RCP_future.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the simulated data is fitted to a lognormal distribution, and we can again see the simulated models (this time from the future time period) all have much lower distributions than the observed record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futparams.groupby('RCP').agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the mean parameter fits for the two representative concentration pathways (RCPs), there is a larger different between the two, as the trend signal is different between the two RCPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the $\\delta_{fut}$ values for each individual model - i.e. the relationship between the quantiles in the reference period and the quantiles in the future period. It is here where we can see the range of outcomes across teh suite of models, and between the two selected emission scenarios. \n",
    "\n",
    "Some models (e.g. ACCESS1-0, MPI-ESM-LRQ) show little difference between reference and future quantiles, and also between the emission scenarios. The CSIRO-MK3.6 and GFDL-ESM2M display a consistent difference across emission scenarios, suggesting an absence of climate sensitivity (at least for $\\Delta p_c$) in those models. The NorESM1-M displays an overall decline in intensity into the future. Counterintuitively, the ACCESS1-3 shows a stronger response in the RCP4.5 emission scenario compared to the RCP8.5, with a siginficant increase in the upper quantiles of $\\Delta p_c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 4, figsize=(20, 20), sharex=True, sharey=True)\n",
    "ax = axes.flatten()\n",
    "x = np.linspace(0, 1, 101)\n",
    "for i, (m, refdf) in enumerate(refdata.items()):\n",
    "    futdf = futdata[m]\n",
    "    model, rcp = m.split(' ')\n",
    "\n",
    "    srefdata = refdf.pdiff.values\n",
    "    sfutdata = futdf.pdiff.values\n",
    "    srefq = np.quantile(srefdata, x)\n",
    "    sfutq = np.quantile(sfutdata, x)\n",
    "    ax[i].scatter(srefq, sfutq, alpha=0.5)\n",
    "    ax[i].plot([0, 50], [0,50], '--', color='k', alpha=0.5)\n",
    "    ax[i].set_title(m, size='small')\n",
    "    ax[i].set_xlim((0, 50))\n",
    "    ax[i].set_ylim((0, 50))\n",
    "    ax[i].set_aspect('equal')\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.text(0.5, 0.01, \"Reference quantiles (hPa)\", ha='center', va='center')\n",
    "fig.text(0.01, 0.5, \"Future quantiles (hPa)\", ha='center', va='center', rotation='vertical')\n",
    "None\n",
    "plt.savefig(pjoin(path, 'ref_fut_quantiles.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a demonstration of the scaling process in practice, here we display the individual $\\Delta p_c$ values for the reference and projection, as well as the observed $\\Delta p_c$ values. On each, we add a line at the 99th percentile for each collection of data. The relative change in the $Q(0.99)$ between the reference period and the future period is 2.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdf = refdata['ACCESS1-3Q RCP45']\n",
    "futdf = futdata['ACCESS1-3Q RCP45']\n",
    "\n",
    "refq099 = np.quantile(refdf.pdiff, 0.99)\n",
    "futq099 = np.quantile(futdf.pdiff, 0.99)\n",
    "obsq099 = np.quantile(obstc.pdiff, 0.99)\n",
    "delta = futq099/refq099 \n",
    "print(delta)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8), sharey=True)\n",
    "ax[0].scatter(refdf.datetime, refdf.pdiff, s=1, c='r')\n",
    "ax[0].scatter(futdf.datetime, futdf.pdiff, s=1, c='r')\n",
    "ax[0].set_xlim(datetime(1981, 1, 1), datetime(2100, 1, 1))\n",
    "ax[0].axhline(refq099, xmin=0, xmax=0.833333, linestyle='--', color='0.5')\n",
    "ax[0].axhline(refq099, xmin=0, xmax=0.25, linestyle='--', color='k')\n",
    "ax[0].axhline(futq099, xmin=0.83333, xmax=1, linestyle='--', color='k')\n",
    "ax[1].scatter(obstc.ISO_TIME, obstc.pdiff, s=1, c='b')\n",
    "ax[1].axhline(obsq099, xmin=0, xmax=0.83333, linestyle='--', color='0.5')\n",
    "ax[1].axhline(obsq099, xmin=0, xmax=0.3333, linestyle='--', color='k')\n",
    "ax[1].axhline(obsq099*delta, xmin = 0.83333, xmax=1, linestyle='--', color='k')\n",
    "ax[1].set_xlim(datetime(1981, 1, 1), datetime(2100, 1, 1))\n",
    "ax[0].set_ylabel(r\"$\\Delta p_c$ hPa\")\n",
    "ax[0].set_xlabel(\"Year\")\n",
    "ax[1].set_xlabel(\"Year\")\n",
    "ax[0].set_title('Modelled')\n",
    "ax[1].set_title('Observed')\n",
    "\n",
    "styles = mpatches.ArrowStyle.get_styles()\n",
    "def to_texstring(s):\n",
    "    s = s.replace(\"<\", r\"$<$\")\n",
    "    s = s.replace(\">\", r\"$>$\")\n",
    "    s = s.replace(\"|\", r\"$|$\")\n",
    "    return s\n",
    "\n",
    "x=datetime(2080, 1, 1)\n",
    "y = 0.5 * (refq099 + futq099)\n",
    "tx=datetime(2060, 1, 1)\n",
    "ty=0.5 * (refq099 + futq099)\n",
    "stylename = '-['\n",
    "ax[0].annotate(r'$\\delta_{fut}$' + ' = {0:.2f}'.format(delta), (x, y),\n",
    "               (tx, ty), xycoords='data',\n",
    "                ha=\"right\", va=\"center\",\n",
    "                size=1.4,\n",
    "                arrowprops=dict(arrowstyle=stylename,\n",
    "                                fc=\"b\", ec=\"b\",\n",
    "                                connectionstyle=\"arc3,rad=-0.05\",\n",
    "                                ),\n",
    "              fontsize='x-small', color='b',\n",
    "              bbox=dict(boxstyle=\"square\", fc=\"w\", alpha=0.5))\n",
    "\n",
    "ax[0].annotate(r\"$Q_{ref}(0.99)$\" + \" = {0:.1f}\".format(refq099), \n",
    "               (datetime(1995, 1, 1), refq099),\n",
    "               (datetime(2000, 1, 1), 3*refq099),\n",
    "               ha=\"center\", va=\"center\", size=1.4,\n",
    "               arrowprops=dict(arrowstyle='->',\n",
    "                                fc=\"b\", ec=\"b\", shrinkB=1.5,\n",
    "                                connectionstyle=\"arc3,rad=-0.0\",\n",
    "                                ),\n",
    "               fontsize='x-small', color='b',\n",
    "              bbox=dict(boxstyle=\"square\", fc=\"w\", alpha=0.5))\n",
    "\n",
    "ax[0].annotate(r\"$Q_{fut}(0.99)$\" + \" = {0:.1f}\".format(futq099), \n",
    "               (datetime(2090, 1, 1), futq099),\n",
    "               (datetime(2080, 1, 1), 2*futq099),\n",
    "               ha=\"center\", va=\"center\", size=1.4,\n",
    "               arrowprops=dict(arrowstyle='->',\n",
    "                                fc=\"b\", ec=\"b\", shrinkB=1.5,\n",
    "                                connectionstyle=\"arc3,rad=-0.0\",\n",
    "                                ),\n",
    "               fontsize='x-small', color='b',\n",
    "              bbox=dict(boxstyle=\"square\", fc=\"w\", alpha=0.5))\n",
    "\n",
    "ax[1].annotate(r\"$Q_{obs}(0.99)$\" + \" = {0:.1f}\".format(obsq099),\n",
    "              (datetime(1995, 1, 1), obsq099),\n",
    "              (datetime(1995, 1, 1), 1.5*obsq099), \n",
    "              ha=\"center\", va='center', size=1.4,\n",
    "              arrowprops=dict(arrowstyle=\"->\",\n",
    "                             fc='b', ec='b', shrinkB=1.5,\n",
    "                             connectionstyle='arc3,rad=-0.05'),\n",
    "              fontsize='x-small', color='b',\n",
    "              bbox=dict(boxstyle=\"square\", fc=\"w\", alpha=0.5))\n",
    "\n",
    "ax[1].annotate(r\"$Q_{futb}(0.99)$\" + \" = {0:.1f}\".format(obsq099 * delta),\n",
    "              (datetime(2090, 1, 1), obsq099 * delta),\n",
    "              (datetime(2060, 1, 1), 1.5*obsq099), \n",
    "              ha=\"center\", va='center', size=1.4,\n",
    "              arrowprops=dict(arrowstyle=\"->\",\n",
    "                             fc='b', ec='b', shrinkB=1.5,\n",
    "                             connectionstyle='arc3,rad=0.5'),\n",
    "              fontsize='x-small', color='b',\n",
    "              bbox=dict(boxstyle=\"square\", fc=\"w\", alpha=0.5))\n",
    "plt.savefig(pjoin(path, 'illustration_qdm.png'), bbox_inches='tight')\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(refq099)\n",
    "print(futq099)\n",
    "print(obsq099)\n",
    "print(obsq099*delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the QDM\n",
    "\n",
    "We begin by running the QDM algorithm for the reference period. This should give $\\delta = 1$, as the 'reference' and 'future' data are the same. This should simplify down to a regular quantile mapping for the distribution between observed and reference period $\\Delta p_c$, and allow for a mapping that can bring the simulated reference period data to a similar distribution to the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata = obstc.pdiff.values[obstc.pdiff.values > 0]\n",
    "fig, axes = plt.subplots(6,4, figsize=(20,20), sharex=True)\n",
    "ax = axes.flatten()\n",
    "brefdata = {}\n",
    "brefparams = pd.DataFrame(columns=['Model', 'RCP', 'mu', 'sigma', 'zeta'])\n",
    "for i, (m, refdf) in enumerate(refdata.items()):\n",
    "    futdf = futdata[m]\n",
    "    model, rcp = m.split(' ')\n",
    "\n",
    "    srefdata = refdf.pdiff.values[refdf.pdiff.values > 0]\n",
    "    brefdata[m] = qdm(obsdata, srefdata, srefdata)\n",
    "    \n",
    "    popt = stats.lognorm.fit(brefdata[m], loc=0, scale=1)\n",
    "    brefparams = brefparams.append({'Model':model, 'RCP':rcp,\n",
    "                                    'mu':popt[0], 'sigma':popt[1], 'zeta':popt[2]},\n",
    "                                   ignore_index=True)\n",
    "    ax[i].scatter(srefdata, brefdata[m], alpha=0.5)\n",
    "    ax[i].plot([-5, 100], [-5, 100], '--')\n",
    "    ax[i].set_xlabel(\"raw-tclv (hPa)\")\n",
    "    ax[i].set_ylabel(\"corrected-tclv (hPa)\")\n",
    "    ax[i].set_title(m)\n",
    "    ax[i].set_xlim((-5, 100))\n",
    "    ax[i].set_ylim((-5, 200))\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the QDM algorithm to the future data to determine the bias corrections for each individual model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata = obstc.pdiff.values[obstc.pdiff.values > 0]\n",
    "fig, axes = plt.subplots(6,4, figsize=(20,20), sharex=True)\n",
    "ax = axes.flatten()\n",
    "bfutparams = pd.DataFrame(columns=['Model', 'RCP', 'mu', 'sigma', 'zeta'])\n",
    "bfutdata = {}\n",
    "for i, (m, refdf) in enumerate(refdata.items()):\n",
    "    futdf = futdata[m]\n",
    "    model, rcp = m.split(' ')\n",
    "    srefdata = refdf.pdiff.values[refdf.pdiff.values > 0]\n",
    "    sfutdata = futdf.pdiff.values[futdf.pdiff.values > 0]\n",
    "    bfutdata[m] = qdm(obsdata, srefdata, sfutdata)\n",
    "    popt = stats.lognorm.fit(bfutdata[m], loc=0, scale=1)\n",
    "    bfutparams = bfutparams.append({'Model':model, 'RCP':rcp,\n",
    "                                    'mu':popt[0], 'sigma':popt[1], 'zeta':popt[2]},\n",
    "                                   ignore_index=True)\n",
    "    ax[i].scatter(sfutdata, bfutdata[m], alpha=0.5)\n",
    "    ax[i].plot([-5, 100], [-5, 100], '--')\n",
    "    ax[i].set_xlabel(\"raw-tclv (hPa)\")\n",
    "    ax[i].set_ylabel(\"corrected-tclv (hPa)\")\n",
    "    ax[i].set_title(m)\n",
    "    ax[i].set_xlim((-5, 100))\n",
    "    ax[i].set_ylim((-5, 200))\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the corrected reference and future period distributions, we observe a significant change in the distribution parameters. Differences between RCP4.5 and RCP8.5 simulations are not significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brefparams.groupby('RCP').agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfutparams.groupby('RCP').agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare the distributions of the reference and future $\\Delta p_c$ values for each model. This is based on the uncorrected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 4, figsize=(20, 20), sharex=True, sharey=True)\n",
    "ax = axes.flatten()\n",
    "\n",
    "x = np.arange(0, 51)\n",
    "for i, row in enumerate(refparams.itertuples()):\n",
    "    m = row.Model\n",
    "    r = row.RCP\n",
    "    refpopt = (row.mu, row.sigma, row.zeta)\n",
    "    futrow = futparams[(futparams.Model==m) & (futparams.RCP==r)]\n",
    "    futpopt = (futrow.mu, futrow.sigma, futrow.zeta)\n",
    "    refpdf = stats.lognorm.pdf(x, *refpopt)\n",
    "    futpdf = stats.lognorm.pdf(x, *futpopt)\n",
    "    ks, pv = stats.ks_2samp(refpdf, futpdf)\n",
    "    ax[i].plot(x, refpdf, 'k', label='Reference')\n",
    "    ax[i].plot(x, futpdf, 'r', label='Future')\n",
    "    ax[i].plot(x, stats.lognorm.pdf(x, *obsparams), 'g', lw=1, label='IBTrACS')\n",
    "    ax[i].set_title('{0} {1}\\n({2:.4f} {3:.4f})'.format(m, r, ks, pv))\n",
    "    if i==0: ax[i].legend(loc=1)\n",
    "        \n",
    "#ax[-1].plot(x, stats.lognorm.pdf(x, *obsparams))\n",
    "#ax[-1].set_title(\"IBTrACS\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(pjoin(path, \"uncorrected.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the ACCESS1-3, CSIRO Mk 3.6.0, GFDL-ESM2M, HadGEM2 and MIROC5 models have a very narrow distribution. This collection of models also have a lower grouping of annual frequency in the reference period - around 13-14 TCLV's per year. The remaining models have a mean annual frequency around 20 in the reference period. \n",
    "\n",
    "Now repeat for the bias-corrected data. In these, the label includes the Kolmogorov-Smirnov (K-S) test statistic and corresponding p-value for a two-sided K-S test for the two distrbutions. A small test statistic, or large p-value, means we cannot reject the null hypothesis that the two samples are drawn from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 4, figsize=(20, 20), sharex=True, sharey=True)\n",
    "ax = axes.flatten()\n",
    "\n",
    "x = np.arange(0, 101)\n",
    "for i, row in enumerate(brefparams.itertuples()):\n",
    "    m = row.Model\n",
    "    r = row.RCP\n",
    "    refpopt = (row.mu, row.sigma, row.zeta)\n",
    "    futrow = bfutparams[(bfutparams.Model==m) & (bfutparams.RCP==r)]\n",
    "    futpopt = (futrow.mu, futrow.sigma, futrow.zeta)\n",
    "    refpdf = stats.lognorm.pdf(x, *refpopt)\n",
    "    futpdf = stats.lognorm.pdf(x, *futpopt)\n",
    "    ks, pv = stats.ks_2samp(refpdf, futpdf)\n",
    "    ax[i].plot(x, refpdf, 'k', label='Reference')\n",
    "    ax[i].plot(x, futpdf, 'r', label='Future')\n",
    "    ax[i].plot(x, stats.lognorm.pdf(x, *obsparams), 'g', lw=1, label='IBTrACS')\n",
    "    ax[i].set_title('{0} {1}\\n({2:.4f} {3:.4f})'.format(m, r, ks, pv))\n",
    "    if i==0: ax[i].legend(loc=1 )\n",
    "        \n",
    "#ax[-1].plot(x, stats.lognorm.pdf(x, *obsparams))\n",
    "#ax[-1].set_title(\"IBTrACS\")\n",
    "fig.tight_layout()\n",
    "None\n",
    "plt.savefig(pjoin(path, \"corrected.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a range of responses between the reference period and the future period. In some models (e.g. ACCESS 1.3 RCP4.5, NorESM1-M RCP4.5) there is virtually no difference in the distributions. In many cases, there is a shift towards higher $\\Delta p_c$ values in the future period. In a small number (GFDL-ESM2M RCP8.5, CSIRO Mk3.6 RCP4.5), the $\\Delta p_c$ distribution shifts towards lower values. The IBTrACS distribution is shown in the lower right corner for reference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,5), sharey=True)\n",
    "x = np.arange(0, 101, 0.5)\n",
    "for i, row in enumerate(brefparams.itertuples()):\n",
    "    refpopt = (row.mu, row.sigma, row.zeta)\n",
    "    refpdf = stats.lognorm.pdf(x, *refpopt)\n",
    "    if i == 0:\n",
    "        ax[0].plot(x, refpdf, 'k', label=\"Reference\", alpha=0.5)\n",
    "    else:\n",
    "        ax[0].plot(x, refpdf, 'k', alpha=0.5)\n",
    "\n",
    "for i, row in enumerate(bfutparams.itertuples()):\n",
    "    futpopt =(row.mu, row.sigma, row.zeta)\n",
    "    futpdf = stats.lognorm.pdf(x, *futpopt)\n",
    "    if i == 0:\n",
    "        ax[1].plot(x, futpdf, 'k', label=\"Projected\", alpha=0.5)\n",
    "    else:\n",
    "        ax[1].plot(x, futpdf, 'k', alpha=0.5)\n",
    "    \n",
    "ax[0].plot(x, stats.lognorm.pdf(x, *obsparams), 'r', label='IBTrACS')\n",
    "ax[1].plot(x, stats.lognorm.pdf(x, *obsparams), 'r', label='IBTrACS')    \n",
    "ax[0].legend(loc=1)\n",
    "ax[1].legend(loc=1)\n",
    "\n",
    "ax[0].set_xlabel(r'$\\Delta p_c$ (hPa)')\n",
    "ax[1].set_xlabel(r'$\\Delta p_c$ (hPa)')\n",
    "ax[0].set_ylabel(\"Probability\")\n",
    "#ax[1].set_ylabel(\"Probability\")\n",
    "fig.tight_layout()\n",
    "None\n",
    "plt.savefig(pjoin(path, \"corrected_distributions.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top panel shows the distribution of bias-corrected $\\Delta p_c$ values for the reference period (1981-2010, black) and the distribution of the IBTrACS data (red). The corrected model distributions very closely line up to the observed distrbution, as is the intention of the algorithm. \n",
    "\n",
    "The lower panel shows the corresponding distributions for the future period bias-corrected $\\Delta p_c$ values. There is a significant variation of the projected distributions of $\\Delta p_c$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,6), sharey=True)\n",
    "x = np.arange(0, 100)\n",
    "\n",
    "for index, row in bfutparams[refparams['RCP']=='RCP45'].iterrows():\n",
    "    popt = (row.mu, row.sigma, row.zeta)\n",
    "    fitline = stats.lognorm.pdf(x, *popt)\n",
    "    ax[0].plot(x, fitline, color='k')\n",
    "ax[0].plot(x, stats.lognorm.pdf(x, *obsparams), 'r')\n",
    "ax[0].set_title(\"RCP4.5\")\n",
    "\n",
    "\n",
    "for index, row in bfutparams[refparams['RCP']=='RCP85'].iterrows():\n",
    "    popt = (row.mu, row.sigma, row.zeta)\n",
    "    fitline = stats.lognorm.pdf(x, *popt)\n",
    "    if index == 1:\n",
    "        ax[1].plot(x, fitline, color='k', label='Projected')\n",
    "    else:\n",
    "        ax[1].plot(x, fitline, color='k')\n",
    "ax[1].plot(x, stats.lognorm.pdf(x, *obsparams), 'r', label='Observations')\n",
    "ax[1].set_title(\"RCP8.5\")\n",
    "fig.tight_layout()\n",
    "ax[0].set_xlabel(r\"$\\Delta p_c$ (hPa)\")\n",
    "ax[1].set_xlabel(r\"$\\Delta p_c$ (hPa)\")\n",
    "ax[1].legend()\n",
    "None\n",
    "plt.savefig(pjoin(path, 'corrected_distribution_by_RCP_future.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the correction to derive new $p_c$ values\n",
    "\n",
    "In this section, we insert the updated $\\Delta p_c$ values back into the source data. This will allow us to use the simulated data as an input to the hazard modelling stage.  \n",
    "\n",
    "At the same time, we calculate an estimate of the maximum sustained wind speed $v_{max}$ for each record. $v_{max}$ is caluclated in the manner described in Holland (2008):\n",
    "\n",
    "$ b_s = -4.4 \\times 10^{-5} \\Delta p^2 + 0.01\\Delta p + 0.03 \\dfrac{\\partial p_c}{\\partial t} - 0.014 \\phi + 0.15 v_t^x +1.0 $\n",
    "\n",
    "$ x = 0.6 ( \\,1 - \\dfrac{\\Delta p}{215} ) \\,$, and\n",
    "\n",
    "$ v_m = ( \\,\\!\\dfrac{b_s}{\\rho e}\\, \\Delta p) \\, ^{0.5} $\n",
    "\n",
    "Air density, $\\rho$, is derived from the virtual temperature and pressure in the region of maximum winds ($R_{mw}$). $v_t$ is the translation speed of the TC and $\\phi$ is the absolute latitude in degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = \"../data/tclv/tracks/corrected\"\n",
    "fileTemplate = \"{0}_bc.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (m, refdf) in enumerate(refdata.items()):\n",
    "    refdf_pos = refdf[refdf['pdiff'] > 0]\n",
    "    refdf_pos['pmin'] = refdf_pos['poci'] - brefdata[m]\n",
    "    refdf_pos['pdiff'] = brefdata[m]\n",
    "    refdf = calculateMaxWind(refdf_pos, 'datetime')\n",
    "    refdata[m] = refdf\n",
    "    fname = pjoin(outputPath, fileTemplate.format(m.replace(' ', '_')))\n",
    "    refdf.to_csv(fname, sep=',', float_format=\"%.3f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(refdata['ENS RCP85']['vmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the future data. Need a different file template so we can include the time period\n",
    "\n",
    "futfileTemplate = \"{0}_{1}-{2}_bc.dat\"\n",
    "for i, (m, futdf) in enumerate(futdata.items()):\n",
    "    futdf_pos = futdf[futdf.pdiff > 0]\n",
    "    futdf_pos['pmin'] = futdf_pos['poci'] - bfutdata[m]\n",
    "    futdf_pos['pdiff'] = bfutdata[m]\n",
    "    futdf = calculateMaxWind(futdf_pos, 'datetime')\n",
    "    futdata[m] = futdf\n",
    "    fname = pjoin(outputPath, futfileTemplate.format(m.replace(' ', '_'), start, end))\n",
    "    futdf.to_csv(fname, sep=',',  float_format=\"%.3f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstc=calculateMaxWind(obstc, 'ISO_TIME')\n",
    "obstc['category'] = pd.cut(obstc['vmax'], [0, 25, 35, 46, 62, 77, 200], labels=labels)\n",
    "sns.distplot(obstc['vmax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are histograms of TC intensity categories for each model, as well as the observed record (lower right panel). Once again there is close agreement between the models for the reference period (1981-2010), both between models and against the observed record. There is a discrepancy between the models and the observed for the 'TD' category (tropical depression, < 17 m/s), with the models indicating a lower proportion of these events. This is likely tied back to the decision to filter short-lived TCLV events. \n",
    "\n",
    "__NOTE__: These histograms are the proportion of TCLV records that are in each category. This does not give an indication of the _frequency_ of different category wind speeds. Each model has a unique change in total TCLV frequency that would need to be applied to this distribution to determine frequency of e.g. category 5 TCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,4, figsize=(20,20), sharex=True, sharey=True)\n",
    "ax = axes.flatten()\n",
    "for i, (m, df) in enumerate(refdata.items()):\n",
    "    df['category'] = pd.cut(df['vmax'], [0, 25, 35, 46, 62, 77, 200], labels=labels)\n",
    "    x = df['category'].value_counts()/len(df)\n",
    "    ax[i].bar(labels, x, color=catpal)\n",
    "    ax[i].set_title(\"{0}\".format(m))\n",
    "    ax[i].set_xlabel('')\n",
    " \n",
    "\n",
    "# Add the IBTrACS as reference\n",
    "#x = obstc['category'].value_counts() / len(obstc)\n",
    "#ax[-1].bar(labels, x, color=catpal)\n",
    "#ax[-1].set_title(\"IBTrACS\")\n",
    "fig.suptitle(\"Reference period\", size=20)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.savefig(pjoin(path, \"categories_reference.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next figure shows the same distributions of TC intensity category for the future period. Here we note significant deviations between the models, as well as differences compared to the observed record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,4, figsize=(20,20), sharex=True, sharey=True)\n",
    "ax = axes.flatten()\n",
    "labels = ['TD', 'TC1', 'TC2', 'TC3', 'TC4', 'TC5']\n",
    "for i, (m, df) in enumerate(futdata.items()):\n",
    "    df['category'] = pd.cut(df['vmax'], [0, 25, 35, 46, 62, 77, 200], labels=labels)\n",
    "    x = df['category'].value_counts()/len(df)\n",
    "    ax[i].bar(labels, x, color=catpal)\n",
    "    ax[i].set_title(\"{0}\".format(m))\n",
    "    ax[i].set_xlabel('')\n",
    " \n",
    "\n",
    "# Add the IBTrACS as reference\n",
    "#x = obstc['category'].value_counts() / len(obstc)\n",
    "#ax[-1].bar(labels, x, color=catpal)\n",
    "#ax[-1].set_title(\"IBTrACS\")\n",
    "fig.suptitle('{0}-{1}'.format(start, end), size=20)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.savefig(pjoin(path, \"categories_future.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(20, 7), sharex=True, sharey=True)\n",
    "ax = axes.flatten()\n",
    "labels = ['TD', 'TC1', 'TC2', 'TC3', 'TC4', 'TC5']\n",
    "\n",
    "df = futdata['ENS RCP45']\n",
    "x = df['category'].value_counts()/len(df)\n",
    "ax[0].bar(labels, x, color=catpal)\n",
    "ax[0].set_title('ENS RCP45')\n",
    "df = futdata['ENS RCP85']\n",
    "x = df['category'].value_counts()/len(df)\n",
    "ax[1].bar(labels, x, color=catpal)\n",
    "ax[1].set_title('ENS RCP85')\n",
    "x = obstc['category'].value_counts() / len(obstc)\n",
    "ax[2].bar(labels, x, color=catpal)\n",
    "ax[2].set_title(\"IBTrACS\")\n",
    "plt.savefig(pjoin(path, \"ensemble_category_projections.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6, 4, figsize=(20, 20), sharex=True, sharey=True,\n",
    "                         subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "ax = axes.flatten()\n",
    "\n",
    "for i, (m, df) in enumerate(futdata.items()):\n",
    "    ax[i].coastlines(resolution='50m', color='black', linewidth=1)\n",
    "    ax[i].add_feature(feature.BORDERS)\n",
    "    ax[i].add_feature(feature.OCEAN, zorder=0)\n",
    "    gl = ax[i].gridlines(linestyle=\":\")\n",
    "    for k,v in df.groupby('num'):\n",
    "        ax[i].plot(v['lon'], v['lat'])\n",
    "        \n",
    "    ax[i].add_patch(mpatches.Rectangle(xy=[135, -25], width=25, height=15,\n",
    "                                fill=False, edgecolor='k', linewidth=3,\n",
    "                                transform=ccrs.PlateCarree(), zorder=100)\n",
    "                    )\n",
    "    \n",
    "    ax[i].set_title(m)\n",
    "None\n",
    "plt.savefig(pjoin(path, \"future_tracks.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, sharex=True, sharey=True, \n",
    "                       figsize=(8, 8),\n",
    "                       subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "ax[0].coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax[0].add_feature(feature.BORDERS)\n",
    "ax[0].add_feature(feature.OCEAN, zorder=0)\n",
    "gl = ax[0].gridlines(linestyle=\":\")\n",
    "df = futdata['ENS RCP45']\n",
    "for k,v in df.groupby('num'):\n",
    "    ax[0].plot(v['lon'], v['lat'])\n",
    "ax[0].add_patch(mpatches.Rectangle(xy=[135, -25], width=25, height=15,\n",
    "                                   fill=False, edgecolor='k', linewidth=3,\n",
    "                                   transform=ccrs.PlateCarree(), zorder=100)\n",
    "                )\n",
    "ax[0].set_title(\"ENS RCP45\")\n",
    "\n",
    "ax[1].coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax[1].add_feature(feature.BORDERS)\n",
    "ax[1].add_feature(feature.OCEAN, zorder=0)\n",
    "gl = ax[1].gridlines(linestyle=\":\")\n",
    "df = futdata['ENS RCP85']\n",
    "for k,v in df.groupby('num'):\n",
    "    ax[1].plot(v['lon'], v['lat'])\n",
    "ax[1].add_patch(mpatches.Rectangle(xy=[135, -25], width=25, height=15,\n",
    "                                   fill=False, edgecolor='k', linewidth=3,\n",
    "                                   transform=ccrs.PlateCarree(), zorder=100)\n",
    "                )\n",
    "ax[1].set_title(\"ENS RCP85\")\n",
    "\n",
    "None\n",
    "plt.savefig(pjoin(path, \"ensemble_future_tracks.png\"), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, sharex=True, sharey=True, \n",
    "                       figsize=(8, 8),\n",
    "                       subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "ax[0].coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax[0].add_feature(feature.BORDERS)\n",
    "ax[0].add_feature(feature.OCEAN, zorder=0)\n",
    "gl = ax[0].gridlines(linestyle=\":\")\n",
    "df = refdata['ENS RCP45']\n",
    "for k,v in df.groupby('num'):\n",
    "    ax[0].plot(v['lon'], v['lat'])\n",
    "ax[0].add_patch(mpatches.Rectangle(xy=[135, -25], width=25, height=15,\n",
    "                                   fill=False, edgecolor='k', linewidth=3,\n",
    "                                   transform=ccrs.PlateCarree(), zorder=100)\n",
    "                )\n",
    "ax[0].set_title(\"ENS RCP45\")\n",
    "\n",
    "ax[1].coastlines(resolution='50m', color='black', linewidth=1)\n",
    "ax[1].add_feature(feature.BORDERS)\n",
    "ax[1].add_feature(feature.OCEAN, zorder=0)\n",
    "gl = ax[1].gridlines(linestyle=\":\")\n",
    "df = refdata['ENS RCP85']\n",
    "for k,v in df.groupby('num'):\n",
    "    ax[1].plot(v['lon'], v['lat'])\n",
    "ax[1].add_patch(mpatches.Rectangle(xy=[135, -25], width=25, height=15,\n",
    "                                   fill=False, edgecolor='k', linewidth=3,\n",
    "                                   transform=ccrs.PlateCarree(), zorder=100)\n",
    "                )\n",
    "ax[1].set_title(\"ENS RCP85\")\n",
    "\n",
    "None\n",
    "plt.savefig(pjoin(path, \"ensemble_reference_tracks.png\"), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
