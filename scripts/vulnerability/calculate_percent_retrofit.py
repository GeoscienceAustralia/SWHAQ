"""
calculate_percent_retrofit.py

Calculate the average fraction of buildings retrofitted in an LGA by repeatedly
randomly selecting buildings to be retrofitted. THere are basic criteria on
which buildings can be retrofitted, but the random sampling means that each
iteration will select a different number of houses in each eligible area. 

""" 

import os
import sys

import warnings
import pandas as pd
import numpy as np

from hazimp import config, context
from hazimp import pipeline

config_file = "/g/data/w85/QFES_SWHA/configuration/hazimp/iterate_hazimp.yaml"
exppath = "/g/data/w85/QFES_SWHA/exposure/2022"
expfile = "SEQ_Residential_Wind_Exposure_2021_TCRM_2022_VulnCurves_AS4055_M4_updated.csv"
expdf = pd.read_csv(os.path.join(exppath, expfile), index_col='LID')
eligibilitypath = "/g/data/w85/QFES_SWHA/exposure/2022"
eligibilityfile = "targeted_retrofit_eligibility.csv"
eligibilitydf = pd.read_csv(os.path.join(eligibilitypath, eligibilityfile), index_col='SA2_MAIN16')
WVC = 'WIND_VULNERABILITY_FUNCTION_ID'
ACC = 'AS4055_CLASS'
TRC = 'Targeted_Retrofit'

LGA_CODES = [31000, 33430, 35010, 35740, 36250, 36720]

def permute_retrofit(df, eligibilitydf):
    # Set some aliases for column names to make the code easier to read
    if TRC in df.columns:
        df.drop(TRC, axis='columns', inplace=True)
    df_retro = pd.merge(df, eligibilitydf[[TRC]],
                        left_on=["SA2_CODE"],
                        right_index=True,
                        how="outer",
                        sort=False)
    df_retro = df_retro.sort_values(TRC).drop_duplicates('internal_id')
    df_retro = df_retro[~df_retro[TRC].isna()]
    #retrofit_percent_new = 0.113
    retrofit_percent_old = 0.48875

    dic_old_RF3 = {
        'dw350': 'dw650',
        'dw351': 'dw651',
        'dw352': 'dw652',
    }

    # modern buildings original vuln functions: retrofit functions (windows)
    #dic_new = {
    #    'dw353': 'dw453',
    #    'dw354': 'dw454',
    #    'dw355': 'dw455',
    #    'dw356': 'dw456',
    #    'dw357': 'dw457',
    #    'dw358': 'dw458',
    #    'dw359': 'dw459',
    #    'dw360': 'dw460',
    #    'dw361': 'dw461',
    #    'dw362': 'dw462',
    #    'dw363': 'dw463',
    #    'dw364': 'dw464',
    #}

    rc1 = ["Eligible"]
    rc2 = ["N3", "N4"]
    list_old_RF3 = list(dic_old_RF3.keys())
    #list_new = list(dic_new.keys())
    # find relevent buildings and sample a percent of them (retrofit_percent)
    #df_new = df_retro[(df_retro[TRC].isin(rc1)) &
    #                  (df_retro[ACC].isin(rc2)) &
    #                  (df_retro[WVC].isin(list_new))]
    #df_new = df_new.sample(frac=retrofit_percent_new)
    df_old_RF3 = df_retro[(df_retro[TRC].isin(rc1)) &
                          (df_retro[ACC].isin(rc2)) &
                          (df_retro[WVC].isin(list_old_RF3))]
    df_old_RF3 = df_old_RF3.sample(frac=(retrofit_percent_old))
    #df_new[WVC] = df_new[WVC].map(dic_new)
    df_old_RF3[WVC] = df_old_RF3[WVC].map(dic_old_RF3)
    #df_retro.update(df_new)
    df_retro.update(df_old_RF3)
    df_retro.drop_duplicates('internal_id', inplace=True)
    return df_retro

colnames=['internal_id', 'LID']
outdf = pd.DataFrame(columns=colnames)

config_list = config.read_config_file(config_file)
cont_in = context.Context()
cont_in.set_prov_label("probabilistic_retrofit_analysis")

calc_jobs = config.instance_builder(config_list)
the_pipeline = pipeline.PipeLine(calc_jobs)
the_pipeline.jobs[0](cont_in)
the_pipeline.jobs[2](cont_in)
base_exp_att = cont_in.exposure_att.copy()
outdf[['internal_id', 'LID']] = cont_in.exposure_att[['internal_id', 'LID']]
outdf.set_index('internal_id', inplace=True)
for iteration in range(100):
    tmpexpdf = permute_retrofit(base_exp_att, eligibilitydf)
    outdf[f"{iteration:03d}"] = 1*(tmpexpdf[WVC] != base_exp_att.loc[tmpexpdf.index, WVC])


# This adds LGA Name and code
outdf = outdf.merge(cont_in.exposure_att.set_index('internal_id')[['LGA_CODE', 'LGA_NAME']],
                    how="inner", left_index=True, right_index=True)

summarydf = outdf.groupby(['LGA_CODE', 'LGA_NAME']).agg('sum')/outdf.groupby(['LGA_CODE', 'LGA_NAME']).count()
summarydf.drop('LID', axis=1, inplace=True)
summarydf.loc[LGA_CODES].quantile([0.05, 0.5, 0.95], axis=1).T.to_csv(os.path.join(exppath, "retrofit_fraction.csv"))